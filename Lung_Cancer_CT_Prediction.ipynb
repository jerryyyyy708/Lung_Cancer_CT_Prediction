{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ac215d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.transforms import ToTensor\n",
    "import torchvision\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score \n",
    "from sklearn.utils import shuffle\n",
    "import pydicom\n",
    "from pydicom.data import get_testdata_files\n",
    "from pydicom import dcmread\n",
    "import time\n",
    "import csv\n",
    "from datetime import date\n",
    "from pytorch_grad_cam import GradCAM\n",
    "%matplotlib inline\n",
    "\n",
    "#report day\n",
    "today=date.today()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e7c61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to take care of teh translation and windowing. \n",
    "# source: https://www.kaggle.com/code/redwankarimsony/ct-scans-dicom-files-windowing-explained/notebook\n",
    "from PIL import Image\n",
    "\n",
    "def window_image(img, window_center,window_width, intercept, slope, rescale=True):\n",
    "    img = (img*slope +intercept) #for translation adjustments given in the dicom file. \n",
    "    img_min = window_center - window_width/2 \n",
    "    img_max = window_center + window_width/2 \n",
    "    img[img<img_min] = img_min \n",
    "    img[img>img_max] = img_max \n",
    "    if rescale: \n",
    "        img = (img - img_min) / (img_max - img_min)*255.0 \n",
    "    return img\n",
    "    \n",
    "def get_first_of_dicom_field_as_int(x):\n",
    "    #get x[0] as in int is x is a 'pydicom.multival.MultiValue', otherwise get int(x)\n",
    "    if type(x) == pydicom.multival.MultiValue: return int(x[0])\n",
    "    else: return int(x)\n",
    "    \n",
    "def get_windowing(data):\n",
    "    dicom_fields = [data[('0028','1050')].value, #window center\n",
    "                    data[('0028','1051')].value, #window width\n",
    "                    data[('0028','1052')].value, #intercept\n",
    "                    data[('0028','1053')].value] #slope\n",
    "    return [get_first_of_dicom_field_as_int(x) for x in dicom_fields]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296dcf42",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Load Dataset\n",
    "if torch.cuda.is_available():  \n",
    "    torch.cuda.empty_cache()\n",
    "    dev = \"cuda:0\" \n",
    "else:  \n",
    "    dev = \"cpu\" \n",
    "    \n",
    "start = time.time()\n",
    "\n",
    "path='LungCT'\n",
    "filelist=os.listdir(path)\n",
    "count=0\n",
    "\n",
    "\n",
    "train_ct_scan=[]\n",
    "train_label=[]\n",
    "\n",
    "test_ct_scan=[]\n",
    "test_label=[]\n",
    "\n",
    "counta=0\n",
    "countb=0\n",
    "#counte=0\n",
    "countg=0\n",
    "\n",
    "train_len_a=0\n",
    "test_len_a=0\n",
    "\n",
    "train_len_b=0\n",
    "test_len_b=0\n",
    "\n",
    "#train_len_e=0\n",
    "#test_len_e=0\n",
    "\n",
    "train_len_g=0\n",
    "test_len_g=0\n",
    "\n",
    "for file in filelist:\n",
    "    if 'A' in file:\n",
    "        if counta < 71:\n",
    "            path2=path+'/'+file+'/'\n",
    "            path2list=os.listdir(path2)\n",
    "            for folder2 in path2list:\n",
    "                path3=path2+folder2+'/'\n",
    "                path3list=os.listdir(path3)\n",
    "                for folder3 in path3list:\n",
    "                    path4=path3+folder3+'/'\n",
    "                    path4list=os.listdir(path4)\n",
    "                    for imgs in path4list:\n",
    "                        imgdata=path4+imgs\n",
    "                        pict=pydicom.read_file(imgdata)\n",
    "                        windows=get_windowing(pict)\n",
    "                        img=window_image(pict.pixel_array[75:437,75:437],windows[0],windows[1],windows[2],windows[3])\n",
    "                        train_ct_scan.append(img.reshape(1,362,362))\n",
    "                        train_label.append(0)\n",
    "                        train_len_a+=1\n",
    "        elif counta < 80:\n",
    "            path2=path+'/'+file+'/'\n",
    "            path2list=os.listdir(path2)\n",
    "            for folder2 in path2list:\n",
    "                path3=path2+folder2+'/'\n",
    "                path3list=os.listdir(path3)\n",
    "                for folder3 in path3list:\n",
    "                    path4=path3+folder3+'/'\n",
    "                    path4list=os.listdir(path4)\n",
    "                    for imgs in path4list:\n",
    "                        imgdata=path4+imgs\n",
    "                        pict=pydicom.read_file(imgdata)\n",
    "                        windows=get_windowing(pict)\n",
    "                        img=window_image(pict.pixel_array[75:437,75:437],windows[0],windows[1],windows[2],windows[3])\n",
    "                        test_ct_scan.append(img.reshape(1,362,362))\n",
    "                        test_label.append(0)\n",
    "                        test_len_a+=1\n",
    "        else:\n",
    "            continue\n",
    "        counta+=1\n",
    "    elif 'B' in file:\n",
    "        if countb < 33:\n",
    "            path2=path+'/'+file+'/'\n",
    "            path2list=os.listdir(path2)\n",
    "            for folder2 in path2list:\n",
    "                path3=path2+folder2+'/'\n",
    "                path3list=os.listdir(path3)\n",
    "                for folder3 in path3list:\n",
    "                    path4=path3+folder3+'/'\n",
    "                    path4list=os.listdir(path4)\n",
    "                    for imgs in path4list:\n",
    "                        imgdata=path4+imgs\n",
    "                        pict=pydicom.read_file(imgdata)\n",
    "                        windows=get_windowing(pict)\n",
    "                        img=window_image(pict.pixel_array[75:437,75:437],windows[0],windows[1],windows[2],windows[3])\n",
    "                        train_ct_scan.append(img.reshape(1,362,362))\n",
    "                        train_label.append(1)\n",
    "                        train_len_b+=1\n",
    "        elif countb < 36:\n",
    "            path2=path+'/'+file+'/'\n",
    "            path2list=os.listdir(path2)\n",
    "            for folder2 in path2list:\n",
    "                path3=path2+folder2+'/'\n",
    "                path3list=os.listdir(path3)\n",
    "                for folder3 in path3list:\n",
    "                    path4=path3+folder3+'/'\n",
    "                    path4list=os.listdir(path4)\n",
    "                    for imgs in path4list:\n",
    "                        imgdata=path4+imgs\n",
    "                        pict=pydicom.read_file(imgdata)\n",
    "                        windows=get_windowing(pict)\n",
    "                        img=window_image(pict.pixel_array[75:437,75:437],windows[0],windows[1],windows[2],windows[3])\n",
    "                        test_ct_scan.append(img.reshape(1,362,362))\n",
    "                        test_label.append(1)\n",
    "                        test_len_b+=1\n",
    "        else:\n",
    "            continue\n",
    "        countb+=1\n",
    "    elif 'G' in file:\n",
    "        if countg < 36:\n",
    "            path2=path+'/'+file+'/'\n",
    "            path2list=os.listdir(path2)\n",
    "            for folder2 in path2list:\n",
    "                path3=path2+folder2+'/'\n",
    "                path3list=os.listdir(path3)\n",
    "                for folder3 in path3list:\n",
    "                    path4=path3+folder3+'/'\n",
    "                    path4list=os.listdir(path4)\n",
    "                    for imgs in path4list:\n",
    "                        imgdata=path4+imgs\n",
    "                        pict=pydicom.read_file(imgdata)\n",
    "                        windows=get_windowing(pict)\n",
    "                        img=window_image(pict.pixel_array[75:437,75:437],windows[0],windows[1],windows[2],windows[3])\n",
    "                        train_ct_scan.append(img.reshape(1,362,362))\n",
    "                        train_label.append(2)\n",
    "                        train_len_g+=1\n",
    "        elif countg < 40:\n",
    "            path2=path+'/'+file+'/'\n",
    "            path2list=os.listdir(path2)\n",
    "            for folder2 in path2list:\n",
    "                path3=path2+folder2+'/'\n",
    "                path3list=os.listdir(path3)\n",
    "                for folder3 in path3list:\n",
    "                    path4=path3+folder3+'/'\n",
    "                    path4list=os.listdir(path4)\n",
    "                    for imgs in path4list:\n",
    "                        imgdata=path4+imgs\n",
    "                        pict=pydicom.read_file(imgdata)\n",
    "                        windows=get_windowing(pict)\n",
    "                        img=window_image(pict.pixel_array[75:437,75:437],windows[0],windows[1],windows[2],windows[3])\n",
    "                        test_ct_scan.append(img.reshape(1,362,362))\n",
    "                        test_label.append(2)\n",
    "                        test_len_g+=1\n",
    "        else:\n",
    "            continue\n",
    "        countg+=1\n",
    "    \n",
    "\n",
    "print(len(train_ct_scan))\n",
    "print(len(test_ct_scan))\n",
    "\n",
    "print()\n",
    "print(train_len_a)\n",
    "print(test_len_a)\n",
    "print()\n",
    "print(train_len_b)\n",
    "print(test_len_b)\n",
    "print()\n",
    "#print(train_len_e)\n",
    "#print(test_len_e)\n",
    "print()\n",
    "print(train_len_g)\n",
    "print(test_len_g)\n",
    "print()\n",
    "\n",
    "\n",
    "end = time.time()\n",
    "print(end - start)\n",
    "train_ct_scan=np.array(train_ct_scan)\n",
    "train_ct_scan=torch.from_numpy(train_ct_scan)\n",
    "train_label=np.array(train_label)\n",
    "train_label=torch.tensor(train_label,dtype=torch.long)\n",
    "test_ct_scan=np.array(test_ct_scan)\n",
    "test_ct_scan=torch.from_numpy(test_ct_scan)\n",
    "test_label=np.array(test_label)\n",
    "test_label=torch.tensor(test_label,dtype=torch.long)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980afe47",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model_1\n",
    "class imgs(Dataset):\n",
    "    def __init__(self,data,target,transform=None):\n",
    "        self.data=data\n",
    "        self.target=target\n",
    "        self.transform=transform\n",
    "    def __len__(self):\n",
    "        return len(self.target)\n",
    "    def __getitem__(self, index):\n",
    "        img = self.data[index]\n",
    "        lbl = self.target[index]\n",
    "        return img, lbl\n",
    "    \n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net,self).__init__()\n",
    "        self.conv1=nn.Conv2d(1,3,7,3,1) #170\n",
    "        self.bn1=nn.BatchNorm2d(3)\n",
    "        self.relu1=nn.ReLU()\n",
    "        self.pool=nn.MaxPool2d(2) #85\n",
    "        self.fc1 = nn.Linear(60*60*3,3)\n",
    "    def forward(self,x):\n",
    "        x=self.conv1(x)\n",
    "        x=self.bn1(x)\n",
    "        x=self.relu1(x)\n",
    "        x=self.pool(x)\n",
    "        x=x.view(-1,60*60*3)\n",
    "        x=self.fc1(x)\n",
    "        return(x)\n",
    "\n",
    "device=dev\n",
    "torch.manual_seed(4712)\n",
    "\n",
    "trainset=imgs(train_ct_scan,train_label)\n",
    "testset=imgs(test_ct_scan,test_label)\n",
    "trainload=DataLoader(trainset,4,shuffle=True)\n",
    "testload=DataLoader(testset,4,shuffle=True)\n",
    "\n",
    "modelname=\"Model_1\"\n",
    "saveepoch=0\n",
    "model=Net().to(device)\n",
    "optimizer = optim.Adadelta(model.parameters(), lr=0.001)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "final_train_accuracy=0\n",
    "final_test_accuracy=0\n",
    "tg=[] #test labels\n",
    "pd=[] #predict labels\n",
    "\n",
    "max_accuracy=0\n",
    "\n",
    "wholestart=time.time()\n",
    "for epoch in range(40):\n",
    "    start=time.time()\n",
    "    tg=[]\n",
    "    pd=[]\n",
    "    train_accuracy=0.0\n",
    "    test_accuracy=0.0\n",
    "    model.train()\n",
    "    for data,target in trainload:\n",
    "        data,target=data.to(device),target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output=model(data.float())\n",
    "        loss=loss_function(output,target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        _,prediction=torch.max(output.data,1)\n",
    "        train_accuracy+=int(torch.sum(prediction==target.data))\n",
    "    train_accuracy=train_accuracy/len(train_label) \n",
    "    model.eval()\n",
    "    \n",
    "    for data,target in testload:\n",
    "        data,target=data.to(device),target.to(device)\n",
    "        output=model(data.float())\n",
    "        _,prediction=torch.max(output.data,1)\n",
    "        test_accuracy+=int(torch.sum(prediction==target.data))\n",
    "        for k in prediction:\n",
    "            pd.append(k.item())\n",
    "        for l in target.data:\n",
    "            tg.append(l.item())\n",
    "    test_accuracy=test_accuracy/len(test_label)\n",
    "    end=time.time()\n",
    "    runtime=end-start\n",
    "    if test_accuracy>max_accuracy:\n",
    "        max_accuracy=test_accuracy\n",
    "        max_matrix=confusion_matrix(tg,pd)\n",
    "        saveepoch=epoch\n",
    "        savetime=time.time()-wholestart\n",
    "        torch.save(model,'net.pt')\n",
    "    print('epoch '+str(epoch+1)+' train acurracy: '+str(train_accuracy)+' test accuracy: '+str(test_accuracy)+' run-time: '+str(runtime))\n",
    "    final_train_accuracy=train_accuracy\n",
    "    final_test_accuracy=test_accuracy\n",
    "\n",
    "print()\n",
    "print(\"Accuracy: \",max_accuracy)\n",
    "print(\"Confusion matrix: \")\n",
    "print(max_matrix)\n",
    "note='selected'\n",
    "to_csv=[modelname,str(today),saveepoch+1,len(train_ct_scan),len(test_ct_scan),max_accuracy,max_matrix[0][0],max_matrix[0][1],max_matrix[0][2],'N/A',max_matrix[1][0],max_matrix[1][1],max_matrix[1][2],'N/A',max_matrix[2][0],max_matrix[2][1],max_matrix[2][2],'N/A','N/A','N/A','N/A','N/A',savetime,note]\n",
    "#print(to_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f490ec58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ResNet50\n",
    "import torchvision.models as models\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, in_channels=1):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.model = models.resnet50(pretrained=True)\n",
    "        self.model.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        num_ftrs = self.model.fc.in_features\n",
    "        self.model.fc = nn.Linear(num_ftrs, 3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a96260",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#ResNet\n",
    "trainset=imgs(train_ct_scan,train_label)\n",
    "testset=imgs(test_ct_scan,test_label)\n",
    "trainload=DataLoader(trainset,4,shuffle=True)\n",
    "testload=DataLoader(testset,4,shuffle=True)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "modelname=\"ResNet\"\n",
    "saveepoch=0\n",
    "\n",
    "model=ResNet().to(device)\n",
    "optimizer = optim.Adadelta(model.parameters(), lr=0.001)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "final_train_accuracy=0\n",
    "final_test_accuracy=0\n",
    "tg=[] #test labels\n",
    "pd=[] #predict labels\n",
    "\n",
    "max_accuracy=0\n",
    "wholestart=time.time()\n",
    "try:\n",
    "    for epoch in range(13):\n",
    "        start=time.time()\n",
    "        tg=[]\n",
    "        pd=[]\n",
    "        train_accuracy=0.0\n",
    "        test_accuracy=0.0\n",
    "        model.train()\n",
    "        for data,target in trainload:\n",
    "            data,target=data.to(device),target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output=model(data.float())\n",
    "            loss=loss_function(output,target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            _,prediction=torch.max(output.data,1)\n",
    "            train_accuracy+=int(torch.sum(prediction==target.data))\n",
    "        train_accuracy=train_accuracy/len(train_label) \n",
    "        model.eval()\n",
    "        for data,target in testload:\n",
    "            data,target=data.to(device),target.to(device)\n",
    "            output=model(data.float())\n",
    "            _,prediction=torch.max(output.data,1)\n",
    "            test_accuracy+=int(torch.sum(prediction==target.data))\n",
    "            for k in prediction:\n",
    "                pd.append(k.item())\n",
    "            for l in target.data:\n",
    "                tg.append(l.item())\n",
    "        test_accuracy=test_accuracy/len(test_label)\n",
    "        end=time.time()\n",
    "        runtime=end-start\n",
    "        if test_accuracy>max_accuracy:\n",
    "            saveepoch=epoch\n",
    "            max_accuracy=test_accuracy\n",
    "            max_matrix=confusion_matrix(tg,pd)\n",
    "            savetime=time.time()-wholestart\n",
    "            torch.save(model,'net.pt')\n",
    "        print('epoch '+str(epoch+1)+' train acurracy: '+str(train_accuracy)+' test accuracy: '+str(test_accuracy)+' run-time: '+str(runtime))\n",
    "        final_train_accuracy=train_accuracy\n",
    "        final_test_accuracy=test_accuracy\n",
    "except KeyboardInterrupt:\n",
    "    print('Interrupted')\n",
    "except RuntimeError:\n",
    "    print('GPU not enough')\n",
    "    \n",
    "\n",
    "print()\n",
    "print(\"Accuracy: \",max_accuracy)\n",
    "print(\"Confusion matrix: \")\n",
    "print(max_matrix)\n",
    "to_csv=[modelname,str(today),saveepoch+1,len(train_ct_scan),len(test_ct_scan),max_accuracy,max_matrix[0][0],max_matrix[0][1],max_matrix[0][2],'N/A',max_matrix[1][0],max_matrix[1][1],max_matrix[1][2],'N/A',max_matrix[2][0],max_matrix[2][1],max_matrix[2][2],'N/A','N/A','N/A','N/A','N/A',savetime,note]\n",
    "\n",
    "#print(to_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46607d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save to report\n",
    "\n",
    "with open('report.csv', 'a',newline='') as report:\n",
    "    writer = csv.writer(report)\n",
    "    writer.writerow(to_csv)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
